{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM9wBIo+wf78jOWLyl3AP5p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anwishn/HoPy/blob/main/%ED%8C%8C%EC%9D%B4%EC%8D%AC%EC%9C%BC%EB%A1%9C_%EB%B0%B0%EC%9A%B0%EB%8A%94_%EB%94%A5%EB%9F%AC%EB%8B%9D_%EA%B5%90%EA%B3%BC%EC%84%9C_ch1%2C_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 머신러닝 개요\n"
      ],
      "metadata": {
        "id": "0hvk0buqGb2q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 머신러닝 기초\n",
        "\n",
        "### 1.1.1 왜 지금 머신러닝이 주목받는가\n",
        "\n",
        "-> 사람이 처리 불가능한 단시간에 대량의 데이터에서 자동으로 정확한 결과를 얻을 수 있다\n",
        "\n",
        "**인공지능 ⊃ 머신러닝 ⊃ 딥러닝**\n",
        "\n",
        "\n",
        "### 1.1.2 머신러닝이란\n",
        "\n",
        "**머신러닝** : 데이터를 반복적으로 학습하여 데이터에 숨어 있는 패턴을 찾아내는 것\n",
        "\n",
        "특징을 배우는 것만으로 기계가 제대로 실물을 이해할 수 있는가 하는 문제 : 기호 접지 문제 \n",
        "\n",
        "=> 머신러닝 방식 (지도학습, 비지도학습, 강화학습)"
      ],
      "metadata": {
        "id": "GpZCyx-JP8Tm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 머신러닝 학습 방식\n",
        "\n",
        "### 1.2.1 **지도학습**\n",
        "\n",
        "\"지도\" : 데이터에 붙어 있는 정답라벨(데이터와 그 내용을 나타내는 카테고리 및 수치)\n",
        "\n",
        "기본 원리 = 대량의 데이터로 컴퓨터가 <u> 정답 라벨</u> 에 근접하도록 반복 처리하는 것\n",
        "\n",
        "1. 분류 문제 : 카테고리를 예측하는 것\n",
        " ex) 0~9의 필기체 문자 인식, 사진에 찍힌 물건의 식별, 문장으로 저자 예측, 얼굴 사진에서 남녀 식별\n",
        "2. 회귀 문제 : 수치값을 예측하는 것\n",
        " ex) 임대료 예측, 매출 예측, 기온 예측, 주가 예측\n",
        "\n",
        "### 1.2.2 **비지도학습**(자율학습)\n",
        "\n",
        " <u>정답라벨(해답) xxx </u> => 정답이나 오답이 없다\n",
        "\n",
        "-> 데이터의 집합 중에서 법칙성이나 데이터의 그룹을 이끌어내는 용도로 사용\n",
        " \n",
        " ex) 클러스터링\n",
        "\n",
        " ### 1.2.3 **강화학습**\n",
        "\n",
        " <u> 지도가 필요 xxx </u>\n",
        " \n",
        " 에이전트와 환경 제공\n",
        " -> 에이전트가 환경에 대해 행동하고, 그 결과로 환경이 에이전트에 보상\n",
        "\n",
        " ex) 이미지 인식, 로봇 제어 등\n",
        "\n"
      ],
      "metadata": {
        "id": "ywBpKgG4P14c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 머신러닝의 흐름과 과적합"
      ],
      "metadata": {
        "id": "cAKUdYzvQdLH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 머신러닝의 흐름\n",
        "\n",
        "### 2.1.1 지도학습의 흐름\n",
        "\n",
        "1) 데이터 수집 \n",
        "\n",
        "2) 데이터 클렌징\n",
        "\n",
        "3) 머신러닝 기법으로 데이터 학습(기준 취득)\n",
        "\n",
        "4) 테스트 데이터로 성능 테스트\n",
        "\n",
        "5) 머신러닝 모델을 웹 환경 등에서 구현\n",
        "\n",
        "+) 1, 2번 과정에 상당한 시간 소요\n",
        "\n",
        "### 2.1.2 데이터 학습(3번 과정)\n",
        "모델 : 컴퓨터 스스로 답을 찾아 데이터의 패턴으로 만든 기준\n",
        "\n",
        "지도학습은 데이터 중에서 패턴을 찾고, 분류하기 위한 모델을 만든다\n",
        "\n"
      ],
      "metadata": {
        "id": "2Z6Rc_C_J3Nl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 학습 데이터 사용법\n",
        "\n",
        "### 2.2.1 훈련 데이터와 테스트 데이터\n",
        "\n",
        "* 훈련 데이터 : 학습에 사용하는 데이터\n",
        "* 테스트 데이터 : 학습된 모델의 정밀도를 평가할 때 사용하는 데이터\n",
        "\n",
        "-> 데이터 나누어 사용, 평가에는 학습에 사용되지 않은 테스트 데이터 사용\n",
        "\n",
        "+) 전체 데이터의 20% 정도를 테스트 데이터로 사용하는 경우가 많다\n",
        "\n",
        "### 2.2.2 홀드아웃 방법의 이론과 실현\n",
        "\n",
        "**홀드아웃 방법** : 주어진 데이터셋을 훈련 데이터와 테스트 데이터 2가지로 분할하는 방법\n",
        "\n",
        "```\n",
        "X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size=XXX, random_state=0)\n",
        "\n",
        "```\n",
        "X = 데이터셋의 정답 라벨에 대응하는 특징이 배열로 되어 있는 데이터\n",
        "\n",
        "y = 데이터셋의 정답 라벨이 배열로 되어 있는 데이터\n",
        "\n",
        "X_train = 훈련 데이터의 데이터셋(정답 라벨 이외)\n",
        "\n",
        "X_test = 테스트 데이터의 데이터셋(정답 라벨 이외)\n",
        "\n",
        "y_train = 훈련 데이터의 정답 라벨\n",
        "\n",
        "y_test = 테스트 데이터의 정답 라벨\n",
        "\n",
        "test_size = (전체 데이터에서 테스트 데이터로 선택하고 싶은 비율, 0과 1 사이의 수치)\n",
        "\n",
        "random_state=0  : 테스트 시 선택되는 데이터셋 고정되도록\n",
        "\n",
        "\n",
        "### 2.2.3 k-분할 교차 검증의 이론\n",
        "\n",
        "**k-분할 교차 검증** : 비복원 추출을 이용하여 훈련 데이터셋을 k개로 분할한 뒤 k-1개의 데이터는 학습 데이터셋으로 사용하고, 나머지 1개를 모델 테스트에 사용하는 방법\n",
        "\n",
        "-> k회 학습과 평가를 반복하고 k개 성능 평가의 평균을 취해 평균 성능 산출\n",
        "\n",
        "+) 모든 조합 시험해 보다 안정되고 정확 but k배의 연산 필요\n",
        "\n",
        "* 리브-원-아웃 교차검증(한 개 뺴기 교차검증)\n",
        ": 분할되는 수를 데이터셋의 수와 같게 하고, 한 줄 이외의 데이터셋으로 학습하고, 학습에 사용하지 않았던 한 줄로 모델의 정밀도를 평가하는 방법\n",
        "\n",
        "### 2.2.4 k-분할 교차검증의 실현\n",
        "\n",
        "```\n",
        "cross_validation.cross_val_score(svc, X, y, cv=(분할수))\n",
        "```"
      ],
      "metadata": {
        "id": "OwR1JTzwQjpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 과적합\n",
        "\n",
        "**과적합**(과대적합) : 주어진 데이터에 과하게 적용되어 올바른 기준을 구축하지 못한 것, 즉 컴퓨터가 데이터를 과하게 학습한 상태\n",
        "\n",
        "과소적합 : 데이터를 제대로 학습하지 못한 상태\n",
        "\n",
        "### 2.3.1 과적합의 회피\n",
        "해결책\n",
        "1. <u>정규화</u> : 편향된 데이터의 영향을 없애는 방법\n",
        "2. 드롭아웃 : 학습시 무작위로 일부 뉴런을 없애는 방법\n",
        "\n",
        "과적합 = 분산이 크다 / 과소적합 = 편향이 크다\n"
      ],
      "metadata": {
        "id": "NI0uWYluQol1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 2.4 앙상블 학습\n",
        "\n",
        "**앙상블 학습** : 여러 모델을 학습시킴으로써 데이터의 일반화를 획득하려는 시도\n",
        "\n",
        "1. 배깅 : 복수의 모델을 동시에 학습시켜 예측 결과의 평균을 취하는 것으로 예측 결과의 일반화 시도\n",
        "2. 부스팅 : 모델의 예측 결과에 대한 모델을 만들어 일반화 성능을 높이는 기술\n"
      ],
      "metadata": {
        "id": "YUkCZhuXQqQM"
      }
    }
  ]
}