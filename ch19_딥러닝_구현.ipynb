{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNPJfK47pg7Rs5+df60nGtM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anwishn/HoPy/blob/main/ch19_%EB%94%A5%EB%9F%AC%EB%8B%9D_%EA%B5%AC%ED%98%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "파이썬으로 배우는 딥러닝 교과서 ch19"
      ],
      "metadata": {
        "id": "l6aAnh9dR8h3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 19. 딥러닝 구현"
      ],
      "metadata": {
        "id": "0q8HnT4eMrOd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 19.1 딥러닝 개요\n",
        "\n",
        "### 19.1.1 딥러닝 체험\n",
        "\n",
        "심층 신경망(Deep Neural Network, **DNN**)\n",
        "-> 라이브러리 Keras(케라스)와 TensorFlow 이용\n",
        "\n",
        "### 19.1.2 딥러닝이란(1)\n",
        "\n",
        "딥러닝 : 동물의 신경망을 참고로 한 심층 신경망 모델을 사용하여 데이터의 분류나 회귀를 실시\n",
        "\n",
        "* 딥러닝이 주목받는 이유 : 인간이 직접 프로그램에 주목할 특징을 지정할 필요가 없다 \n",
        "\n",
        "### 19.1.3 딥러닝이란(2)\n",
        "\n",
        "* 신경망의 기본이 되는 뉴런 구조\n",
        "\n",
        "   x1,x2가 입력, w1,w2가 가중치 파라미터 \n",
        "\n",
        " -> w1x1+w2x2 의 값이 임곗값 θ보다 높으면 1 출력, 그렇지 않으면 0 출력\n",
        "\n",
        "* 이러한 뉴런을 여러 층 구축해 => 심층 신경망\n",
        "\n",
        "딥러닝에서는 각 뉴런의 가중치 파라미터를 기계적으로 조정하여 분류 모델이나 회귀 모델 만든다\n",
        "\n",
        "### 19.1.4 딥러닝을 이용한 분류의 흐름\n",
        "\n",
        "1) 네트워크 모델 작성하기\n",
        ": 여러 뉴런을 묶은 층을 거듭해 심층 네트워크 구축\n",
        "* 입력층, 은닉층, 출력층\n",
        "\n",
        "2) 모델에 훈련용 데이터를 부여하고 학습시키기\n",
        "\n",
        "x를 입력받아 y 출력 -> 출력 y와 정답 데이터(지도 라벨) T와의 차이 작게 하기 위해 -> **각 뉴런의 가중치 조정** by 오차역전파법 -> x와 T 제공하여 **반복적으로 학습** 후 적절한 예측값을 반환하는 모델\n",
        "\n",
        "3) 분류할 데이터를 모델에 전달하기\n",
        "\n",
        "실제로 학습이 끝난 모델을 사용하여 예측할 데이터를 모델에 전달하고 추론(추론 단계) -> 모델의 정확도 계산"
      ],
      "metadata": {
        "id": "AFdHb5LIMvWA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 19.2 필기체 숫자의 분류\n",
        "\n",
        "### 19.2.1 분류의 흐름\n",
        "\n",
        "Keras라는 파이썬 라이브러리 사용\n",
        "\n",
        "1) 데이터 준비 -> 2) 신경망 모델 구축 -> 3) 모델에 데이터를 전달해서 학습시킴 -> 4) 모델의 분류 정확도 평가\n",
        "\n",
        "### 19.2.2 심층 신경망\n",
        "\n",
        "심층 신경망\n",
        "\n",
        "* 입력층 : 입력을 맡은 층\n",
        "* 출력층 : 출력하는 층\n",
        "* 은닉층 : 입력층과 출력층 사이의 층\n",
        "* 노드 : 세로로 늘어선 벡터 하나하나의 요소 ( 차원 수 = 노드 수)\n",
        "\n",
        "+) 원-핫 벡터 : 단 하나의 값만 True이고, 나머지는 모두 False\n",
        "\n",
        "### 19.2.3 Keras 도입\n",
        "\n",
        "Keras : TensorFlow의 래퍼 라이브러리, 보다 직관적이며 간결하게 코드 작성 가능\n",
        "\n",
        "### 19.2.4 데이터 준비\n",
        "\n",
        "* Keras에서 MNIST import\n",
        "```\n",
        "from keras.datasets import mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "```\n",
        "\n",
        "### 19.2.5 모델 생성\n",
        "\n",
        "1) 모델 관리하는 인스턴스 만들기\n",
        "\n",
        "```\n",
        "model = Sequential()\n",
        "```\n",
        "\n",
        "2) 모델을 한 층씩 정의 - **add()** 메서드 사용\n",
        "\n",
        "```\n",
        "model.add(Dense(128))  # 유닛 수가 128인 전결합층 정의\n",
        "model.add(Activation(\"sigmoid\"))    # 활성화 함수를 적용해 각 전결합층 출력\n",
        "```\n",
        "\n",
        "3) 어떠한 학습을 실시할지 설정 - **compile()** 메서드 사용\n",
        "\n",
        "```\n",
        "model.compile(optimizer=sgd, loss=\"categorical_crossentropy\"metrics=\"accuracy\"])\n",
        "```\n",
        "\n",
        "### 19.2.6 모델 학습 \n",
        "\n",
        "```\n",
        "model.fit(X_train, y_train, verbose=1, epochs=3)\n",
        "```\n",
        "**fit()** 메서드 : 학습용 데이터를 순서대로 모델에 입력, 출력 및 지도 데이터 간의 차이가 작아지도록 각 뉴런의 가중치 조금씩 갱신 => 오차 감소, 모델의 예측 정확도 향상\n",
        "\n",
        "X_train : 학습용 입력 데이터 / y_train : 지도 데이터\n",
        "\n",
        "verbose : 학습의 진척 상황 표시 조정(1로 지정 시 진척 출력, 0으로 지정 시 진척 출력x)\n",
        "\n",
        "epochs : 동일한 데이터셋으로 몇 번 반복 학습할지 지정\n",
        "\n",
        "\n",
        "### 19.2.7 모델 평가\n",
        "\n",
        "```\n",
        "score = model.evaluate(X_test, y_test, verbose=1)\n",
        "```\n",
        "\n",
        "**evaluate()** 메서드 : 모델에 테스트 데이터를 전달했을 때의 분류 정확도(일반화 정확도)의 계산 => 손실 함수의 값과 정확도\n",
        "\n",
        "X_test : 평가용 입력 데이터 / y_test : 지도 데이터\n",
        "\n",
        "+) 테스트 데이터로 학습하는 것은 바람직 x\n",
        "\n",
        "\n",
        "### 19.2.8 모델에 의한 분류\n",
        "\n",
        "```\n",
        "pred = np.argmax(model.predict(X_test[0]))  # \n",
        "print(\"예측치 :\"+ str(pred))\n",
        "```\n",
        "\n",
        "**predict()** : 예측치 얻어 / 여러 장의 이미지를 인수로 받아들이는 것을 가정 => 사진 1장을 예측하는 경우 차원에 주의\n",
        "\n",
        "출력이 10차원 -> argmax() 함수로 가장 큰 값을 반환하는 뉴런의 위치 취득  (행렬 축 지정 해야돼)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "w33HE0SYU_u8"
      }
    }
  ]
}